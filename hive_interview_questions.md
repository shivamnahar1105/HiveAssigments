# Hive Interview Questions

#### 1. What is the definition of Hive? What is the present version of Hive?

-- Hive is an open-source data warehouse system that is built on top of Hadoop. It provides a SQL-like interface to query and analyze large datasets stored in Hadoop's distributed file system (HDFS) or other compatible file systems. Present version is 3.1.3.

#### 2. Is Hive suitable to be used for OLTP systems? Why?

-- OLTP systems are designed for handling a large number of small and frequent transactions, such as bank transactions or e-commerce purchases. In contrast, Hive is designed for OLAP (Online Analytical Processing) systems that deal with larger and less frequent queries.

Hive is optimized for handling complex queries over large datasets and performing batch processing, rather than handling numerous small transactions in real-time. Hive's underlying architecture, including the use of Hadoop Distributed File System (HDFS) and MapReduce, makes it more suitable for processing large volumes of data at once rather than handling individual transactions in real-time.

Therefore, if you need a system to handle OLTP workloads, you should consider other technologies that are specifically designed for that purpose, such as relational databases like MySQL or PostgreSQL.

#### 3. How is HIVE different from RDBMS? Does hive support ACID transactions. If not then give the proper reason.

-- Hive is different from traditional RDBMS (Relational Database Management System) in several ways:

> Data model: RDBMS stores data in a structured manner, using tables with predefined schema, whereas Hive stores data in a semi-structured or unstructured format, such as CSV, JSON or Avro, using a schema-on-read approach.

> Query language: RDBMS uses SQL (Structured Query Language) for querying and manipulating data, whereas Hive uses a SQL-like query language called HiveQL (Hive Query Language), which is optimized for querying large datasets.

> Scalability: RDBMS typically works on a single server, whereas Hive is designed to work with large datasets distributed across a cluster of computers.

Hive does not fully support ACID (Atomicity, Consistency, Isolation, and Durability) transactions. While it does support some ACID-like properties, such as atomicity and durability, it lacks full support for consistency and isolation.

The reason for this is that Hive is built on top of Hadoop, which was originally designed for batch processing and not for transactional workloads. Hadoop's underlying file system, HDFS, is also designed to support large-scale batch processing rather than real-time transaction processing. As a result, Hive's architecture is optimized for efficient processing of large volumes of data rather than transaction processing.

However, there are other technologies that can be used with Hive to provide transactional capabilities, such as Apache HBase or Apache Phoenix. These technologies are designed to work with Hadoop and provide ACID transactions for real-time workloads.

#### 4. Explain the hive architecture and the different components of a Hive architecture?

Hive architecture consists of several components, each performing a specific function:

> Metastore: The Metastore is the central repository that stores metadata about the data stored in Hive. It includes information about the database schema, tables, partitions, columns, and their data types. It also stores the location of the data in the Hadoop Distributed File System (HDFS) or other compatible file systems.

> HiveQL: HiveQL is the SQL-like language used to query the data stored in Hive. It is a high-level language that gets translated into MapReduce jobs that execute on the Hadoop cluster.

> Driver: The Driver is the main component responsible for executing the Hive queries. It receives the query from the user, converts it into MapReduce jobs, and submits them to the Hadoop cluster for execution. It also communicates with the Metastore to get information about the data being queried.

> Compiler: The Compiler is responsible for parsing the HiveQL queries and converting them into an execution plan. The execution plan is then optimized for performance and translated into MapReduce jobs.

> Execution Engine: The Execution Engine is responsible for executing the MapReduce jobs generated by the Compiler. It communicates with the Hadoop cluster to execute the MapReduce jobs and fetches the results back to the Driver.

> Hadoop Cluster: The Hadoop Cluster is the underlying infrastructure that runs the MapReduce jobs generated by Hive. It consists of a cluster of computers that work together to store and process large volumes of data.

> Storage: Hive can store data in several formats, including text, CSV, ORC, Parquet, and Avro. The data is stored in HDFS or other compatible file systems, and the Metastore keeps track of the location of the data.

Overall, the Hive architecture is designed to provide a SQL-like interface for querying large volumes of data stored in Hadoop or other compatible file systems. It uses a high-level language (HiveQL) to convert queries into MapReduce jobs, which are executed on the Hadoop cluster. The Metastore stores metadata about the data, while the Execution Engine executes the MapReduce jobs and fetches the results back to the user.

![image](https://user-images.githubusercontent.com/118034802/234181817-c8391cdb-5107-4ac1-b6e5-47649fffe73b.png)

#### 5. Mention what Hive query processor does? And Mention what are the components of a Hive query processor?

The Hive query processor is responsible for processing the queries submitted to Hive and generating an execution plan for the queries. The query processor is composed of several components, each performing a specific function:

* Parser: The Parser is responsible for parsing the HiveQL queries submitted by the user and converting them into an abstract syntax tree.

* Semantic Analyzer: The Semantic Analyzer checks the syntax of the query and performs semantic analysis, including resolving table and column names, and checking for the correctness of the query syntax.

* Query Optimizer: The Query Optimizer generates an optimized execution plan for the query by considering various factors such as join order, filter order, and partition pruning. The optimizer also chooses the most efficient join algorithm and selects the best parallelism degree for the query.

* Query Planner: The Query Planner generates a logical execution plan for the query, which is a set of instructions for how the query should be executed.

* Execution Engine: The Execution Engine is responsible for executing the logical execution plan generated by the Query Planner. It translates the logical execution plan into a physical execution plan that can be executed on the Hadoop cluster. The Execution Engine is also responsible for scheduling and coordinating the execution of the query.

Overall, the Hive query processor is a complex system that works together to generate an optimized execution plan for the queries submitted by the user. It uses a series of components to parse, analyze, optimize, plan, and execute the queries, taking into consideration various factors such as data location, data format, and query complexity.

#### 6. What are the three different modes in which we can operate Hive?

There are three different modes in which we can operate Hive:

* Local Mode: In Local Mode, Hive runs on a single machine and uses the local file system to store data. This mode is useful for testing and debugging queries on small datasets.

* MapReduce Mode: In MapReduce Mode, Hive uses MapReduce to process data stored in Hadoop Distributed File System (HDFS) or other compatible file systems. This mode is suitable for large datasets that require distributed processing.

* Spark Mode: In Spark Mode, Hive uses Apache Spark as the execution engine to process data stored in HDFS or other compatible file systems. This mode is suitable for large datasets that require distributed processing and can provide better performance than MapReduce Mode.

In addition to these modes, Hive also supports different deployment modes such as Standalone, Pseudo-distributed, and Fully-distributed mode, which determine the number of nodes and the type of installation used for running Hive.

#### 7. Features and Limitations of Hive.
Hive is a data warehousing tool that enables users to perform data analysis using SQL-like queries. It has several features that make it a popular tool for big data analysis, including:

> Features:

* SQL-like Query Language: Hive provides a SQL-like query language, HiveQL, which makes it easy for users familiar with SQL to write and execute queries.

* Scalability: Hive is designed to handle large datasets and can scale to process terabytes or petabytes of data.

* Integration with Hadoop: Hive is tightly integrated with Hadoop and can leverage Hadoop's distributed computing framework to process data in a distributed manner.

* Extensibility: Hive provides a framework for adding custom user-defined functions (UDFs) and SerDes to handle different data formats.

* Schema on Read: Hive enables users to define the structure of data on read rather than on write, which provides flexibility in working with structured and semi-structured data.

* Security: Hive provides several security features, including authentication and authorization, to control access to data.

> Limitations:

* Latency: Hive is not designed for real-time processing and can have high latency, especially when running complex queries on large datasets.

* Limited Support for Transactions: Hive does not support ACID transactions, which can make it challenging to maintain data consistency.

* Limited Support for Updates and Deletes: Hive is optimized for batch processing and does not provide efficient support for updates and deletes of data.

* Lack of Indexing: Hive does not provide indexing for non-primary key columns, which can result in slow query performance on large datasets.

* Limited Support for Complex Data Types: Hive has limited support for complex data types, such as arrays and maps, which can make it challenging to work with semi-structured data.

Overall, Hive is a powerful tool for big data analysis that provides several useful features but also has some limitations that users should be aware of when deciding whether to use it for their data analysis needs.







#### 8. How to create a Database in HIVE?

```
create database database_name;
```

#### 9. How to create a table in HIVE?

```
CREATE TABLE table_name (
  column1 data_type,
  column2 data_type,
  ...
) 
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS textfile;
```






